---
title: Proyecto "Parkinson Telemonitoring"
author: Antonio Miguel Morillo Chica
date: 30/05/2018
output: pdf_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library("tinytex")
library("rmarkdown")
library("caret")
library("rpart")
library("leaps")
library("e1071")
library("maptree")
library("FNN")
library("party")
library("gbm")
library("lattice")
library("randomForest")
library("MASS")
set.seed(3)	# se establece la semilla
```

# 1. Parkinson Telemonitoring

## 1.1. Entender el problema a resolver. 
El proyecto que voy ha desarrollar usa la base de datos "Parkinson Telemonitoring". Esta base de datos se compone de una gama de mediciones de voz biomédica de 42 personas con enfermedad de Parkinson en etapa temprana contratadas para una prueba de seis meses de un dispositivo de telemonitorización para la monitorización remota de la progresión de los síntomas. Las grabaciones fueron capturadas automáticamente en el hogar del paciente. 

Los datos están en formato ASCII-CSV. Las filas del archivo CSV contienen una instancia correspondiente a una grabación de voz. Hay alrededor de 200 grabaciones por paciente, el número de sujeto del paciente se identifica en la primera columna. 

  > **El objetivo principal será predecir los valores de motor_UPDRS y total_UPDRS.**

## 1.2. Lectura de los datos.
La base de datos está compuesta por un archivo donde encontramos 5879 ejemplos con 26 columnas, la primera identifica al paciente y el resto corresponde a 25 caracteristicas que son:

  - **Sexo**: 0 es hombre, 1 es mujer.
  - **test_time** - Tiempo del reclutamiento, la parte entera representa el número de dias. 
  - **motor_UPDRS** - Escala de puntuación UDPRS (Unified Parkinson’s Disease Rating Scale) **que deberemos de pronosticar**
  - **total_UPDRS** - Escala de puntuación UDPRS (Unified Parkinson’s Disease Rating Scale) **que deberemos de pronosticar**
  - **Jitter(%),Jitter(Abs),Jitter:RAP,Jitter:PPQ5,Jitter:DDP** - Varias medidas de variación en la frecuencia.
  - **Shimmer,Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,Shimmer:APQ11,Shimmer:DDA** - Varias medidas de variación en la amplitud
  - **NHR,HNR** - Dos medidas de proporción de ruido a componentes tonales en la voz.
  - **RPDE** - Una medida de complejidad dinámica no lineal
  - **DFA** - Exponente de escala de fractal de señal
  - **PPE** - Una medida no lineal de la variación de frecuencia fundamental.
  

Lo primero que haremos será leer el conjunto del archivo csv, como este ya contiene una fila con los nombres por columna, lo leemos, de igual forma sabemos que el separador de datos de una misma fila es una coma por lo que lo indicamos aunque no haría falta. 

```{r}
datos <- read.csv("./datos/parkinsons_updrs.data", head=T, sep = ",")
```

  Como los datos de partida están contenidos en el mismo archivo lo que vamos a hacer es dividir el conjunto de datos en dos, un conjunto train que nos servirá para entrenar los modelos y un train para probar la efectividad de nuestro aprendizaje. De igual forma he de recalcar que no he realizado validación cruzada aunque para obtener unos resultados más "reales" esto sería muy conveniente. 
  
  Por otro lado he decidido eliminar 4 caracteristicas que no me parecen relevantes, aunque más que no ser relevantes me voy a basar unicamente en las caracteristicas de la voz sin tener en cuenta el sexo.

```{r}
# Eliminamos: sujeto, edad, sexo y test_time:
datos <- datos[,-(1:4)]
summary(datos)

# Elegimos los indices para el train, 80% de los datos 
idx.Train = sample(nrow(datos),size = nrow(datos)*0.8)

# Formamos loc conjuntos train y test. 
train <- as.data.frame(datos[idx.Train,])
test  <- as.data.frame(datos[-idx.Train,])

cat("Dim train : ", dim(train), "\n")
cat("Dim test  : ", dim(test ), "\n")
Sys.sleep(3)
```


## 1.3. Tratamiento basico de los datos (normalización)

  Para este apartado haremos dos tareas muy sencillas y una tercera que dejaremos para más delante. La primera es averiguar variables que provoquen que la varianza sea cercana a 0 cosa que no nos interesa ya extraeremos poca información de estas características y lo único que harán serán entorpecer al modelo de aprendizaje. 

```{r}
nearZeroVar(train)
nearZeroVar(test)
```

  Como podemos ver en la salida nos dice que no existe ninguna caracteristica cuya varianza sea proxima a 0 por lo que asumismos que por ahora las caracteristicas usadas son buenas y variadas, serán buenos predictores. Ahora vamos a ver si existen valores perdidos, esto es, valores para características cuyo valor es $Na$. 
  
```{r}
perdidos.train <- sum(is.na(train))
perdidos.test  <- sum(is.na(test ))

cat("Num valores perdidos: ", perdidos.train, ",", perdidos.test,"\n")
Sys.sleep(3)
```

  Vemos como el número de valores perdidos es 0 por lo que no deberemos tratarlos.
  
  El último punto de esta sección tendría que ver con la normalización pero no la aplicaremos ya que primero vamos a ver los resultados de los modelos sin que los datos estén preProcesados, pero, ¿es bueno hacer un preprocesado, normalizar etc.?
  
  En el tratamiento y analisis masivo de datos nos encontramos todo el tiempo que datos sucios, ruido o valores inconsistentes por lo que obviamente cuanta mejor sea la calidad de las mediciones, no existan inconsistencias, como valores perdidos, caracteristicas que no aportan información alguna o información contradictoria (ej. sexo: hombre, embarazada: sí) lo mejor será resolverlas. Además, la normalización ayuda casi siempre al modelo ya que "elimina" valores extremos que pueden conducirnos a un mal aprendizaje. 
  
## 1.5 Modelos que vamos a usar. 

  Existen multitud de modelos que podemos usar para problemas de regresión pero nos vamos a centrar en un modelo lineal concreto, **Regresión Lineal** y tres no son lineales, SVM (Support Vector Machine), Boosting y RF (RandomForest). Que explicaremos a continuación. 
  
  - **Regresión Lineal**: Es el modelo más básico de aprendizaje y del que más hemos estudiado en teoría. El modelo asume que, dado un conjunto de datos  $ \{y_i, x_{i1}, ..., x_{ip}\}^n_{i=1} $ de $n$ unidades estadísticas, un modelo lineal asume que la relación entre la variable dependiente $y$ y el $p-vector$ de regresores x es lineal. Esta relación se modela a través de un término de perturbación o variable de error $e$, una variable aleatoria no observada que agrega "ruido" a la relación lineal entre la variable dependiente y los regresores.
  
```{r}
# Aprendemos del train
modelo.lm1 = lm(motor_UPDRS ~ . - total_UPDRS, data = train)
modelo.lm2 = lm(total_UPDRS ~ . - motor_UPDRS, data = train)

# Mostramos la interpretación que ha hecho el modelo
par (mfrow = c (2,2))
plot(modelo.lm1)
plot(modelo.lm2)
Sys.sleep(3)
```

  - **SVM** (Support Vector Machine): Este modelo busca un hiperplano que separe de forma óptima a los puntos de una clase de la de otra, que eventualmente han podido ser previamente proyectados a un espacio de dimensionalidad superior. En el concepto de "separación óptima" es donde reside la característica fundamental de SVM: este tipo de algoritmos buscan el hiperplano que tenga la máxima distancia (margen) con los puntos que estén más cerca de él mismo. La manera más simple de realizar la separación es mediante una línea recta, un plano recto o un hiperplano N-dimensional. Desafortunadamente los universos a estudiar no se suelen presentar en casos idílicos de dos dimensiones he aquí donde tenemos que tener en cuenta el "kernel" que vamos a usar. 
  
  En nuestro caso vamos a usar un nucleo gaussiano que es el nucleo por defecto que usa la librería caret para svm. El parámetro libre está para los dos modelos es por defecto.
  
```{r}
# Aprendemos cual es el mejor valor libre de dos cifras. 
obj1 = best.tune(svm, motor_UPDRS ~ . - total_UPDRS, data = train)
obj2 = best.tune(svm, total_UPDRS ~ . - motor_UPDRS, data = train)
print(obj1)
print(obj2)
```

  El mejor gamma para SVM como podemos ver es: por lo que vamos a aprender el modelo con este parámetro. Se puede buscar el parámetro de la siguiente forma ``` best.tune(svm, total_UPDRS ~ . - motor_UPDRS, data = train, ranges = list(epsilon = seq(0,1,0.01), cost = 2^(2:9))) ``` pero la ejecución es demasiado lenta para ejecutar la documentación.

```{r}
# Aprendemos del train usando ese gamma
modelo.svm1 = svm(motor_UPDRS ~ . - total_UPDRS, 
                  data = train, gamma = 0.06, epsilon = 0.1)
modelo.svm2 = svm(total_UPDRS ~ . - motor_UPDRS, 
                  data = train, gamma = 0.06, epsilon = 0.1)
```

  - **Boosting**: El boosting consiste en combinar los resultados de varios clasificadores débiles para obtener un clasificador robusto. Cuando se añaden estos clasificadores débiles, se lo hace de modo que estos tengan diferente peso en función de la exactitud de sus predicciones. Luego de que se añade un clasificador débil, los datos cambian su estructura de pesos: los casos que son mal clasificados ganan peso y los que son clasificados correctamente pierden peso. Así, los clasificadores débiles se centran de mayor manera en los casos que fueron mal clasificados por los clasificadores débiles.
  
```{r}
modelo.gbm1 = gbm(motor_UPDRS ~ . - total_UPDRS, data = train)
modelo.gbm2 = gbm(total_UPDRS ~ . - motor_UPDRS, data = train)
print(modelo.gbm1)
print(modelo.gbm2)

plot(modelo.gbm1)
plot(modelo.gbm2)
Sys.sleep(3)
```

  - **RT** (Random Forest): Es una combinación de árboles predictores tal que cada árbol depende de los valores de un vector aleatorio probado independientemente y con la misma distribución para cada uno de estos. Es una modificación sustancial de bagging que construye una larga colección de árboles no correlacionados y luego los promedia.
  
  Como es un problema de regresión por defecto Random Forest del paquete que he usado toma como m=p/3 donde p es el número de características. Además usa unos 500 arboles por defecto. Una vez pintemos el modelo nos daremos cuenta de los parámetro optimos que en nuestro caso es 100 arboles como vemos en las fraficas, cuando ajustemos el modelo buscaremos el mejor m, mtry para RandomForest.
  
```{r}
# Aprendemos el modelo
modelo.rf1 = randomForest(motor_UPDRS ~ . - total_UPDRS, data = train)
modelo.rf2 = randomForest(total_UPDRS ~ . - motor_UPDRS, data = train)

par (mfrow = c (1,2))
plot(modelo.rf1)
plot(modelo.rf2)
Sys.sleep(3)
```

## 1.6 Evaluación de los modelos. 
  Una vez creados los modelos y haberlos entrenado tenemos que ver los resultados, recordemos que aún no hemos normalizado los datos por lo que los resultados no son definitivos. Por cada método tenemos dos modelos, uno que pronostica los valores $motor_UPDRS$ y otro para $total_UPDRS$. He creado una pequeña función para este cometido. La función evalua el $E_{in}$ y el $E_{out}$. 

```{r}
eval_model <- function(model,type=1, Boosting = F) {
          
  ein <- 0
  eout <- 0
  # Para boosting neceesitamos el número de arboles que van a ser
  # usados para pronosticar, que los ajustaremos a 100. 
  if(Boosting == FALSE){
    pred_train <- predict(model,newdata = train)
    pred_test <- predict(model,newdata = test)
    # Tipo indica si estamos hablando de motor_UDPRS o total_UDPRS
    if (type == 1) {
      ein <- sqrt(mean((pred_train-train$motor_UPDRS)^2))
      eout <- sqrt(mean((pred_test-test$motor_UPDRS)^2))
    }else{
      ein<- sqrt(mean((pred_train-train$total_UPDRS)^2))
      eout<- sqrt(mean((pred_test-test$total_UPDRS)^2))
    } 
  }else{
    pred_train <- predict(model,newdata = train, n.trees = 100)
    pred_test <- predict(model,newdata = test, n.trees = 100)

    if (type == 1) {
      ein<- sqrt(mean((pred_train-train$motor_UPDRS)^2))
      eout<- sqrt(mean((pred_test-test$motor_UPDRS)^2))
    }else{
      ein<- sqrt(mean((pred_train-train$total_UPDRS)^2))
      eout<- sqrt(mean((pred_test-test$total_UPDRS)^2))
    } 
  }
  
  return (c(ein,eout))
}
```

  La medida de error que he usado es el error cuadratico medio que se define de la sigiente forma: Si $S$ es un vector de $n$ predicciones e $Y$ el vector de valores verdaderos entonces la estimación de ECM sería:
  
  $ECM = \frac{1}{n} \sum_{i=1}^{n} (S_i - Y_i)^2$
  
  Vamos ahora a evaluar los modelos obtenidos y a ver sus resultados.
  
```{r}
eval.lm1 = eval_model(modelo.lm1,1)
eval.lm2 = eval_model(modelo.lm2,2)

eval.svm1 = eval_model(modelo.svm1,1)
eval.svm2 = eval_model(modelo.svm2,2)

eval.rf1 = eval_model(modelo.rf1,1)
eval.rf2 = eval_model(modelo.rf2,2)

eval.gbm1 = eval_model(modelo.gbm1,1,T)
eval.gbm2 = eval_model(modelo.gbm2,2,T)

cat("LM    \n     motor_UPDRS - Ein: ", eval.lm1[1], 
    "      \n     total_UPDRS - Ein: ", eval.lm2[1],
    
    "\nSVM \n     motor_UPDRS - Ein: ", eval.svm1[1],
    "      \n     total_UPDRS - Ein: ", eval.svm2[1],

    "\nBST \n     motor_UPDRS - Ein: ", eval.gbm1[1],
    "      \n     total_UPDRS - Ein: ", eval.gbm2[1],
    
    "\nRF  \n     motor_UPDRS - Ein: ", eval.rf1[1], 
    "      \n     total_UPDRS - Ein: ", eval.rf2[1])
Sys.sleep(3)

```

  Como podemos ver los resultados son bastante buenos, en general el Ein es muy bajo pero claro, estamos viendo el valor del error sobre los datos que hemos aprendido por lo que deberiamos esperarnos un error muy bajo y ha sido así. Sin embargo debemos de ver el Ein ya que nos indicará si nuestros modelos predicen de forma correcta o si estamos cometiendo un sobreaprendidaje. 
  
```{r}
cat(
    "\nLM  \n     motor_UPDRS - Eout: ", eval.lm1[2], 
    "      \n     total_UPDRS - Eout: ", eval.lm2[2],

    "\nSVM \n     motor_UPDRS - Eout: ", eval.svm1[2],
    "      \n     total_UPDRS - Eout: ", eval.svm2[2],

    "\nBST \n     motor_UPDRS - Eout: ", eval.gbm1[2],
    "      \n     total_UPDRS - Eout: ", eval.gbm2[2],
    
    "\nRF  \n     motor_UPDRS - Eout: ", eval.rf1[2], 
    "      \n     total_UPDRS - Eout: ", eval.rf2[2])
Sys.sleep(3)
```

  Podemos observar que no hemos cometido ningún tipo de sobreaprendizaje, es más, el error medio es bajo, ningún modelo supera el 10% y claramente Random Forest es el mejor modelo con los parámetros prestablecidos. 
  
  Vamos a aplicar normalización a los datos para ver como cambian las predicciones realizadas por los modelos. Tras esto vamos a ajustar el mejor modelo hasta el momento. 

## 1.7. Preprocesando los datos.
  Para el preprocesado vamos a usar la librería caret, como tenemos 18 caracteristicas bajo mi punto de vista no hace falta aplicar un métodos de preProcesado como PCA (Analisis Principales Componentes) aunque como prueba lo hemos voy a mostrar veremos que se reducen el número de características enormente. 
  
  El preProcesado que vamos a hacer es una estandarización, esto es aplicar dos transformaciones, scala y centro que provocan que los atributos tengan un valor medio 0 y una desviación standar de 1:
  
```{r}
# Calculamos la transformación
trans = preProcess(train, method = c("center","scale"))
trans2 = preProcess(train, method = c("center","scale", "pca"))

# Obtenemos el nuevo conunto de datos.
train = predict(trans, train)
test = predict(trans, test)

train.pca = predict(trans2, train)
test.pca = predict(trans2, test)

cat("Dim Train con PCA: ", dim(train.pca))
Sys.sleep(3)
```

  Como podemos observar la dimensión si hubiesemos aplicado PCA se reduce muchísimo peor vamos a usar solo los datos con la estandarización. 
  
  Vamos ahora a calcular los nuevos modelos con los nuevos datos transformados:

```{r}
# Aprendemos de nuevo los modelos
modelo2.lm1 = lm(motor_UPDRS ~ . - total_UPDRS, data = train)
modelo2.lm2 = lm(total_UPDRS ~ . - motor_UPDRS, data = train)
modelo2.svm1 = svm(motor_UPDRS ~ . - total_UPDRS,
                   data = train, gamma = 0.06, epsilon = 0.1)
modelo2.svm2 = svm(total_UPDRS ~ . - motor_UPDRS,
                   data = train, gamma = 0.06, epsilon = 0.1)
modelo2.rf1 = randomForest(motor_UPDRS ~ . - total_UPDRS, data = train)
modelo2.rf2 = randomForest(total_UPDRS ~ . - motor_UPDRS, data = train)
modelo2.gbm1 = gbm(motor_UPDRS ~ . - total_UPDRS, data = train)
modelo2.gbm2 = gbm(total_UPDRS ~ . - motor_UPDRS, data = train)

# Evaluamos los modelos
eval2.lm1 = eval_model(modelo2.lm1,1)
eval2.lm2 = eval_model(modelo2.lm2,2)
eval2.svm1 = eval_model(modelo2.svm1,1)
eval2.svm2 = eval_model(modelo2.svm2,2)
eval2.rf1 = eval_model(modelo2.rf1,1)
eval2.rf2 = eval_model(modelo2.rf2,2)
eval2.gbm1 = eval_model(modelo2.gbm1,1,T)
eval2.gbm2 = eval_model(modelo2.gbm2,2,T)
```

  Mostramos los nuevos resultaados: 

```{r}
# Mostramos el Ein
# -----------------------------------------------------
cat("LM    \n     motor_UPDRS - Ein: ", eval2.lm1[1], 
    "      \n     total_UPDRS - Ein: ", eval2.lm2[1],
    
    "\nSVM \n     motor_UPDRS - Ein: ", eval2.svm1[1],
    "      \n     total_UPDRS - Ein: ", eval2.svm2[1],

    "\nBST \n     motor_UPDRS - Ein: ", eval2.gbm1[1],
    "      \n     total_UPDRS - Ein: ", eval2.gbm2[1],
    
    "\nRF  \n     motor_UPDRS - Ein: ", eval2.rf1[1], 
    "      \n     total_UPDRS - Ein: ", eval2.rf2[1])
Sys.sleep(3)

# Mostramos el Eout
# ------------------------------------------------------
cat(
    "\nLM  \n     motor_UPDRS - Eout: ", eval2.lm1[2], 
    "      \n     total_UPDRS - Eout: ", eval2.lm2[2],

    "\nSVM \n     motor_UPDRS - Eout: ", eval2.svm1[2],
    "      \n     total_UPDRS - Eout: ", eval2.svm2[2],

    "\nBST \n     motor_UPDRS - Eout: ", eval2.gbm1[2],
    "      \n     total_UPDRS - Eout: ", eval2.gbm2[2],
    
    "\nRF  \n     motor_UPDRS - Eout: ", eval2.rf1[2], 
    "      \n     total_UPDRS - Eout: ", eval2.rf2[2])
Sys.sleep(3)
```

  Gracias a la standarización hemos obtenido unos nuevos resultados muy buenos. Todos los modelos han bajado su error medio mucho pero Random Forest sigue siendo el mejor modelo, el que mejor hace predicciones sobre este problema por lo que pasará a ser el modelo que vamos a ajustar.
  
## 1.8. Ajuste del modelo final.
  Para el ajuste del modelo final de random fores voy a usar diferentes valores de para m. La variable m identifica al número de caracteristicas aleatorias que vamos a cambiar por arbol de decisión. En clase hemos visto tres valores que podemos usar que son los siguientes: 
  - m=p
  - m=p/2
  - m=sqrt(p)
  
  Como he dicho anteriormente de forma predeterminada Random Forest usa 500 arboles y un m=p/3. 

```{r}
# Aprendemos los modelos
rf.ajuste1 = randomForest(motor_UPDRS ~ . - total_UPDRS, data = train, 
                          ntree=200, importance = T, mtry=dim(train)[2]-1)
rf.ajuste2 = randomForest(total_UPDRS ~ . - motor_UPDRS, data = train, 
                          ntree=200, importance = T, mtry=dim(train)[2]-1)

rf.ajuste3 = randomForest(motor_UPDRS ~ . - total_UPDRS, data = train, 
                          ntree=200, importance = T, mtry=dim(train)[2] / 2)
rf.ajuste4 = randomForest(total_UPDRS ~ . - motor_UPDRS, data = train, 
                          ntree=200, importance = T, mtry=dim(train)[2] / 2)

rf.ajuste5 = randomForest(motor_UPDRS ~ . - total_UPDRS, data = train, 
                          ntree=200, importance = T, mtry=sqrt(dim(train)[2]))
rf.ajuste6 = randomForest(total_UPDRS ~ . - motor_UPDRS, data = train, 
                          ntree=200, importance = T, mtry=sqrt(dim(train)[2]))

# Los evaluamos 
rf.eval1 = eval_model(rf.ajuste1,1)
rf.eval2 = eval_model(rf.ajuste2,2)
rf.eval3 = eval_model(rf.ajuste3,1)
rf.eval4 = eval_model(rf.ajuste4,2)
rf.eval5 = eval_model(rf.ajuste5,1)
rf.eval6 = eval_model(rf.ajuste6,2)
```

```{r}
# Mostramos los resultados: 
cat("\nRF m=p 
          \n     motor_UPDRS - Ein: ", rf.eval1[1], 
         "\n     total_UPDRS - Ein: ", rf.eval2[1],
         "\n     motor_UPDRS - Eout: ", rf.eval1[2], 
         "\n     total_UPDRS - Eout: ", rf.eval2[2])

cat("\nRF m=p/2 
          \n     motor_UPDRS - Ein: ", rf.eval3[1], 
         "\n     total_UPDRS - Ein: ", rf.eval4[1],
         "\n     motor_UPDRS - Eout: ", rf.eval3[2], 
         "\n     total_UPDRS - Eout: ", rf.eval4[2])

cat("\nRF m=sqrt(p) 
          \n     motor_UPDRS - Ein: ", rf.eval5[1], 
         "\n     total_UPDRS - Ein: ", rf.eval6[1],
         "\n     motor_UPDRS - Eout: ", rf.eval5[2], 
         "\n     total_UPDRS - Eout: ", rf.eval6[2])
Sys.sleep(3)
```

El ajuste del modelo ha sido efectivo y hemos mejorado en 0,01% el error, algo practicamente insignificannte pero porque nuestro modelo es muy bueno. Además podemos destacar que efectivamente no estamos cometiendo sobreajuste cosa de la que nos hubiesemos dado cuenta comparando los direntes Ein y Eout. 


















